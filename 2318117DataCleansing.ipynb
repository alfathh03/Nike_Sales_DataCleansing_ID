{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPwtbwAK/mX7gn1twuaXFWD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alfathh03/Nike_Sales_DataCleansing_ID/blob/master/2318117DataCleansing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. INSTAL LIBRARY"
      ],
      "metadata": {
        "id": "kKps6woOJtWx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "    Mengimpor pustaka Pandas untuk memanipulasi data tabular (DataFrame), NumPy untuk operasi numerik, dan io untuk mengolah data yang diunggah\n",
        "\n",
        "    Metode yang Digunakan: Library Initialization"
      ],
      "metadata": {
        "id": "nxTFcOiN44i1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "X1SBjK1m34Fl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Koneksi Google Drive"
      ],
      "metadata": {
        "id": "_f7bjqczJxVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "    Mengimpor modul 'files' dari google.colab,"
      ],
      "metadata": {
        "id": "e8OBIcK96s0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Digunakan untuk memungkinkan fitur unggah dan unduh file di lingkungan Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "XThW25X648tl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44d905a5-2e09-4ff3-cef5-282971c82325"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Buka File Dataset"
      ],
      "metadata": {
        "id": "yTix0G71J0mI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/Colab Notebooks/dataset/data kotor.csv'\n",
        "df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "IwTl78eDJ99-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Penanganan Data yang Hilang (Missing Values) dan Imputasi"
      ],
      "metadata": {
        "id": "xgvKnHyJKm52"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "    Bagian ini adalah tahapan inti pembersihan data. Kami menerapkan serangkaian keputusan metodologis untuk mengatasi data yang hilang (NaN)"
      ],
      "metadata": {
        "id": "4cEw3wsB_7ll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat salinan data untuk proses pembersihan.\n",
        "df_clean = df.copy()\n",
        "\n",
        "# A. Hapus Baris Total Kosong:\n",
        "# Menghapus baris yang tidak memiliki ID Pesanan.\n",
        "df_clean.dropna(subset=['ID_Pesanan'], inplace=True)\n",
        "\n",
        "# B. Imputasi Numerik (Mengisi NaN):\n",
        "# Mengisi NaN pada Diskon_Diterapkan dengan 0.\n",
        "df_clean['Diskon_Diterapkan'] = df_clean['Diskon_Diterapkan'].fillna(0)\n",
        "\n",
        "# Mengisi NaN pada Unit_Terjual dengan 0\n",
        "df_clean['Unit_Terjual'] = df_clean['Unit_Terjual'].fillna(0)\n",
        "\n",
        "# Mengganti nilai Unit_Terjual yang negatif menjadi 0\n",
        "df_clean.loc[df_clean['Unit_Terjual'] < 0, 'Unit_Terjual'] = 0\n",
        "\n",
        "# Konversi ke integer setelah bersih dari nilai negatif\n",
        "df_clean['Unit_Terjual'] = df_clean['Unit_Terjual'].astype(int)\n",
        "\n",
        "# Mengecek apakah ada nilai negatif pada kolom Unit_Terjual\n",
        "negatif_unit = df_clean[df_clean['Unit_Terjual'] < 0]\n",
        "print(\"Data dengan Unit_Terjual negatif:\")\n",
        "print(negatif_unit)\n",
        "\n",
        "# --- Penanganan ---\n",
        "# Opsi 1: Ganti nilai negatif dengan 0 (sudah dilakukan di atas)\n",
        "# Opsi 2 (alternatif): Ganti nilai negatif dengan median kolom\n",
        "# median_unit = df_clean['Unit_Terjual'].median()\n",
        "# df_clean.loc[df_clean['Unit_Terjual'] < 0, 'Unit_Terjual'] = median_unit\n",
        "\n",
        "# Cek ulang apakah masih ada nilai negatif\n",
        "print(\"Sisa data dengan Unit_Terjual negatif:\", (df_clean['Unit_Terjual'] < 0).sum())\n",
        "\n",
        "# Mengisi NaN pada MRP dengan nilai median per Lini Produk.\n",
        "df_clean['Harga_Eceran_Maksimum'] = df_clean.groupby('Lini_Produk')['Harga_Eceran_Maksimum'].transform(\n",
        "    lambda x: x.fillna(x.median())\n",
        ")\n",
        "\n",
        "# C. Imputasi Kategorikal:\n",
        "# Mengisi nilai NaN pada kolom Ukuran dengan Modus.\n",
        "df_clean['Ukuran'] = df_clean['Ukuran'].fillna(df_clean['Ukuran'].mode()[0])\n"
      ],
      "metadata": {
        "id": "jFScyuS5AjQ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a247094-2eaa-4b0b-fe06-10fcd8b38d39"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data dengan Unit_Terjual negatif:\n",
            "Empty DataFrame\n",
            "Columns: [ID_Pesanan, Kategori_Gender, Lini_Produk, Nama_Produk, Ukuran, Unit_Terjual, Harga_Eceran_Maksimum, Diskon_Diterapkan, Pendapatan, Tanggal_Pesanan, Saluran_Penjualan, Wilayah, Keuntungan]\n",
            "Index: []\n",
            "Sisa data dengan Unit_Terjual negatif: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Koreksi Tipe Data dan Penanganan Inkonsistensi Logis"
      ],
      "metadata": {
        "id": "xRRGfA0oKyzw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "    Bagian ini berfokus pada validasi dan standardisasi struktural data. Kami mengonversi kolom ID menjadi tipe bilangan bulat (integer) dan memperbaiki format Tanggal_Pesanan menjadi tipe datetime untuk memungkinkan analisis temporal. Lebih lanjut, kami menghapus anomali fatal di mana kerugian dicatat tanpa adanya pendapatan yang jelas, karena kondisi ini secara logis mustahil dan mengindikasikan error pencatatan yang parah\n",
        "\n",
        "    Metode yang digunakan: Type Casting dan Anomaly Handling (Penghapusan Logis)\n",
        "  "
      ],
      "metadata": {
        "id": "cAx0CpvWAs3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A. Koreksi Tipe Data\n",
        "# Mengonversi ID Pesanan menjadi integer.\n",
        "df_clean['ID_Pesanan'] = df_clean['ID_Pesanan'].astype(int)\n",
        "\n",
        "# Mengonversi Tanggal Pesanan ke format datetime.\n",
        "df_clean['Tanggal_Pesanan'] = pd.to_datetime(df_clean['Tanggal_Pesanan'], errors='coerce')\n",
        "\n",
        "# Jika ada nilai kosong (NaT) pada Tanggal_Pesanan, ganti dengan 0\n",
        "df_clean['Tanggal_Pesanan'] = df_clean['Tanggal_Pesanan'].fillna(0)\n",
        "\n",
        "# B. Penanganan Inkonsistensi Logis:\n",
        "# Menghapus baris di mana Pendapatan = 0 DAN Keuntungan < 0.\n",
        "df_clean = df_clean[~((df_clean['Pendapatan'] == 0) & (df_clean['Keuntungan'] < 0))]\n"
      ],
      "metadata": {
        "id": "8kHsKRe3AvT7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.  Standarisasi Kolom Ukuran"
      ],
      "metadata": {
        "id": "_9i79zY9K_wi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "    Bagian ini fokus pada standardisasi data kategorikal. Nilai numerik yang tidak baku pada kolom Ukuran dikelompokkan ke dalam kategori standar (S, M, L, XL) untuk memastikan konsistensi analisis"
      ],
      "metadata": {
        "id": "0_IzSyRVE6yg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STANDARDISASI UKURAN ---\n",
        "\n",
        "# Membuat peta pemetaan dari ukuran non-standar/numerik ke standar (S, M, L, XL)\n",
        "size_mapping = {\n",
        "    # Numerik ke Kategori\n",
        "    '6': 'S', '7': 'S',\n",
        "    '8': 'M', '9': 'M',\n",
        "    '10': 'L', '11': 'L',\n",
        "    '12': 'XL',\n",
        "    # Kategori sudah ada (untuk memastikan)\n",
        "    'M': 'M', 'L': 'L', 'XL': 'XL'\n",
        "}\n",
        "\n",
        "# Mengonversi kolom Ukuran ke string untuk menangani nilai numerik dan teks secara seragam\n",
        "df_clean['Ukuran'] = df_clean['Ukuran'].astype(str)\n",
        "\n",
        "# Menerapkan pemetaan standardisasi ukuran\n",
        "df_clean['Ukuran'] = df_clean['Ukuran'].replace(size_mapping)\n",
        "\n",
        "print(\"\\nStandardisasi kolom 'Ukuran' berhasil diterapkan.\")\n",
        "print(\"Nilai unik akhir di kolom Ukuran:\", df_clean['Ukuran'].unique())"
      ],
      "metadata": {
        "id": "cqGIBKm0EkMb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b2869d2-12b0-40b4-f92b-e8cd39d01b69"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Standardisasi kolom 'Ukuran' berhasil diterapkan.\n",
            "Nilai unik akhir di kolom Ukuran: ['M' 'L' 'XL' 'S']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.  Ringkasan Akhir dan Penyimpanan Hasil"
      ],
      "metadata": {
        "id": "pHviVXieLJm0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "    Sebagai tahap finalisasi dan penutupan, blok ini memberikan ringkasan status data (perbandingan jumlah baris awal dan akhir) dan menyajikan data yang telah dibersihkan. Selanjutnya, data yang sudah tervalidasi tersebut disimpan ke dalam file CSV baru dan secara otomatis diunduh ke perangkat pengguna.\n",
        "\n",
        "    Metode yang Digunakan: Data Serialization (Serialisasi Data) dan Validation"
      ],
      "metadata": {
        "id": "i5MEz6loA0Zh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files  # WAJIB diimport\n",
        "\n",
        "# Ringkasan Akhir dan Penyimpanan\n",
        "print(f\"Bentuk Awal Data: {df.shape[0]} baris\")\n",
        "print(f\"Bentuk Akhir Data Bersih: {df_clean.shape[0]} baris\")\n",
        "\n",
        "print(\"\\n5 Baris Pertama Data yang Sudah Dibersihkan:\")\n",
        "print(df_clean.head().to_markdown(index=False))\n",
        "\n",
        "# Menyimpan DataFrame yang sudah dibersihkan ke file CSV baru.\n",
        "output_file_name_clean = 'Nike_Penjualan_Dibersihkan_Final.csv'\n",
        "df_clean.to_csv(output_file_name_clean, index=False)\n",
        "\n",
        "# Mengunduh file hasil (fitur Colab).\n",
        "files.download(output_file_name_clean)\n",
        "print(f\"\\nDataset akhir telah disimpan sebagai '{output_file_name_clean}' dan diunduh ke komputer Anda.\")\n"
      ],
      "metadata": {
        "id": "d6jPlIhjA0nk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "5dbd7786-6797-4ac2-bba1-e96ae7d7f293"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bentuk Awal Data: 2499 baris\n",
            "Bentuk Akhir Data Bersih: 587 baris\n",
            "\n",
            "5 Baris Pertama Data yang Sudah Dibersihkan:\n",
            "|   ID_Pesanan | Kategori_Gender   | Lini_Produk   | Nama_Produk    | Ukuran   |   Unit_Terjual |   Harga_Eceran_Maksimum |   Diskon_Diterapkan |   Pendapatan | Tanggal_Pesanan     | Saluran_Penjualan   | Wilayah   |   Keuntungan |\n",
            "|-------------:|:------------------|:--------------|:---------------|:---------|---------------:|------------------------:|--------------------:|-------------:|:--------------------|:--------------------|:----------|-------------:|\n",
            "|         2002 | Wanita            | Sepak Bola    | Premier III    | M        |              4 |                 5937.52 |                   0 |            0 | 0                   | Ritel               | Mumbai    |      3337.34 |\n",
            "|         2003 | Anak              | Gaya Hidup    | Blazer Mid     | L        |              0 |                 9673.57 |                   0 |            0 | 2024-04-10 00:00:00 | Daring              | Pune      |      3376.85 |\n",
            "|         2004 | Anak              | Lari          | React Infinity | XL       |              0 |                 5714.92 |                   0 |            0 | 2024-09-12 00:00:00 | Ritel               | Delhi     |       187.89 |\n",
            "|         2005 | Wanita            | Latihan       | Flex Trainer   | M        |              1 |                 7363.96 |                   0 |            0 | 0                   | Ritel               | Delhi     |      1415.98 |\n",
            "|         2006 | Pria              | Latihan       | SuperRep Go    | M        |              0 |                 6819.78 |                   0 |            0 | 2025-04-06 00:00:00 | Daring              | Bangalore |      1802.09 |\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_008dafbe-5253-4398-8ca3-55ddae701848\", \"Nike_Penjualan_Dibersihkan_Final.csv\", 51903)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset akhir telah disimpan sebagai 'Nike_Penjualan_Dibersihkan_Final.csv' dan diunduh ke komputer Anda.\n"
          ]
        }
      ]
    }
  ]
}